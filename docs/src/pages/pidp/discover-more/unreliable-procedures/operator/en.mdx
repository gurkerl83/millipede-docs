# Evaluation of the handling by the provider of a digital platform

## Handling by the provider

### General

Large companies that operate powerful social media platforms have an internal
set of guidelines that determine whether content reported by a user meets the
criterion to be considered critical in its message.

#### Outsourcing as responsibility avoidance

Some companies, such as Facebook, do not employ staff for deletion requests
themselves but delegate the editorial classification of the content to external
service providers. The employees must have the necessary competence to fulfill
this responsibility since an incorrect or faulty procedure in evaluating a
deletion request represents a considerable interference in the free formation of
the opinion of the individual. Despite an internal catalog of guidelines and
requirements created within the company, which defines the framework conditions
for critical content, it is doubtful whether every employee has the training to
assess or evaluate the content properly.

#### Health consequences due to critical content

However, the caseworker is periodically confronted with such critical content,
which causes a direct impact on consciousness (reaction). Frequently repeated
confrontation can lead to the traumatization of the person. The effect of
content classified in a gray zone should not be underestimated; it can result in
a gradual blunting of perception and thus cause a change in personal values and
opinions.

> This problem shows that in each case, the practice demonstrated by a company
> must be questioned as to whether and which journalistic standards are adhered
> to ensure a high quality of decision-making (research). If a wrong decision is
> made, which as a consequence removes neutral content from a digital platform,
> this is similar to the process of censorship.
